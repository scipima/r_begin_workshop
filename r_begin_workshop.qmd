---
title: "Data Analysis and Visualisation with R"
format:
  html:
    code-fold: true
    code-summary: "Show the code"
editor_options: 
  chunk_output_type: console
---

## Learning objectives

* Get familiar with an IDE.
* Know how to set up a data research project.
* Visualise data: choose an appropriate visualisation for your data; understand the layered approached typical of `ggplot2`.
* Be able to read in, process, and store data.


## Intro
For this workshop, we borrow heavily from [Data Visualization for Social Science](https://socviz.co/index.html#preface).
This very markdown is based off the R package accompanying the book. 
You can use it to take notes, write your code, and produce a good-looking, reproducible document that records the work you have done. 

At the very top of the file is a section of *metadata*, or information about what the file is and what it does. 
The metadata is delimited by three dashes at the start and another three at the end.
You should change the title, author, and date to the values that suit you. 
Keep the `output` line as it is for now, however. 
Each line in the metadata has a structure. 
First the *key* ("title", "author", etc), then a colon, and then the *value* associated with the key.  
It is very picky when it comes with indentations, characters used, etc.


### This is a Quarto File
[Markdown](http://rmarkdown.rstudio.com) is a simple formatting syntax for authoring HTML, PDF, and MS Word documents, and is also the basis for [Quarto](https://quarto.org/). 

When you click the **Render** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. 
A *code chunk* is a specially delimited section of the file. 
You can add one by moving the cursor to a blank line choosing Code > Insert Chunk from the RStudio menu. 
When you do, an empty chunk will appear:
```{r}
```

Code chunks are delimited by three backticks (found to the left of the 1 key on US and UK keyboards) at the start and end.
The opening backticks also have a pair of braces and the letter `r`, to indicate what language the chunk is written in. 
You write your code inside the code chunks. 
Write your notes and other material around them, as here. 


## Know your editor
Please have a look at your screen.
Some of the most important things to learn now:

* Console
* Editor
* Environment

For this workshop, we rely on RStudio.
An alternative you may explore is [VS Code](https://code.visualstudio.com/). 


## Before you begin to explore and analyse, set up your workspace
A number of functions and packages come already installed in what is generally referred to as `R base` (and you can actually see what's in it by typing `base::` in your console, and let the auto-complete suggest you the full list of functions ... ).
However, most of the things we'll do in this workshop need further `libraries`.
To install the `tidyverse`, make sure you have an Internet connection. 
Then *manually* run the code in the chunk below. 
If you just render the document, this will be skipped - **however, if this is the first time you run this, make sure to manually run the code chunk below**. 
We do this because you only need to install these packages once, not every time you run this file. 
Either knit the chunk using the little green "play" arrow to the right of the chunk area, or copy and paste the text into the console window.
```{r}
#| include: false
#| eval: false

# This code will not be evaluated automatically. 
# Notice the eval = FALSE declaration in the options section of the code chunk

my_packages <- c("tidyverse", "broom", "coefplot", "cowplot",
                 "gapminder", "GGally", "ggrepel", "ggridges", "gridExtra",
                 "here", "interplot", "margins", "maps", "mapproj",
                 "mapdata", "MASS", "quantreg", "rlang", "scales",
                 "survey", "srvyr", "viridis", "viridisLite", "devtools")
install.packages(my_packages)
devtools::install_github("kjhealy/socviz")
```


## Set Up Your Project and Load Libraries
To begin we must load some libraries we will be using. 
If we do not load them, R will not be able to find the functions contained in these libraries. 
The `tidyverse` includes `ggplot2` (for data visualisation) and other libraries such as `dplyr` (for data manipulation).
We also load the `socviz` and `gapminder` libraries.
```{r}
#| include: false

## Load the libraries we will be using
library(tidyverse)
library(here)
library(gapminder)
library(ggrepel)
library(socviz)
```

Notice that here an option is set: `include=FALSE`. 
This tells R to run this code but not to include the output in the final document. 

When you click the **Render** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.
You can embed an R code chunk like this:
```{r}
gapminder
```

A final note about the `here` [library](https://here.r-lib.org/).
That is a great help if you have properly set up your project as I just indicated. 
All paths will become relatively, and you can forget about remembering where you are in your machine. 
The essential thing is that it relies on the `.RProject` file that is created automatically for you when you create a `Project` with `RStudio`. 


## Data Visualisation
### Few initial words
R has a consolidated role in data visualisation, well beyond the initial remit of statistics. 
A few examples:

* R at FT: https://johnburnmurdoch.github.io/slides/r-ggplot/#/
* Resources compiled by people from Posit: https://themockup.blog/static/slides/intro-plot#1


### Let's start with some actual code
Let's go back to the `gapminder` data we saw before. 
What kind of variable are we dealing with?
Let's remind ourselves.
```{r}
head(gapminder)
```

We can explore the data in a more structure way, by checkin what classes dow we have as columns.
```{r}
str(gapminder) # classes and first values
glimpse(gapminder) # very similar, tidyverse way
summary(gapminder) # main stats
# knitr::kable(gapminder) |> head()
```

Say that we have an hypothesis regarding how life expectancy (`lifeExp`) changes in relations with GDP per capita (`gdpPercap`). 
As these look like continuous variables, we could plot them in a scatterplot.
There are at least two ways to create a plot within `ggplot`.

* We can assign a ggplot plot to an object called `p` (the name doesn't matter, we can call it `mike` if we want to), and then add (literally, using `+`) layers on top of it.
```{r}
p <- ggplot(data= gapminder,
            mapping = aes(x= gdpPercap,
                          y= lifeExp))
p + geom_point() # and you can keep on adding to this, see below ... 
```

* Another way of achieving the same thing is as follows, which is more in line with a tidyverse style which heavily rely on pipes (`|>`). 
```{r}
#| eval: false
gapminder |>
  ggplot(aes(x= gdpPercap, y= lifeExp)) + 
  geom_point()
```

Sometimes, when we face a cloud like the one above, it is useful to plot a trendline on top, to understand the overall pattern. 
```{r}
# geom_smooth() using method = 'gam' and formula 'y ~ s(x, bs = "cs")' - GAM stands for generalised additive model
p + geom_point() + 
  geom_smooth() 
```

Perhaps that is too wiggly.
Using method='lm' (linear model) as an argument to geom_smooth() includes a simple OLS regression.
This also should make you aware of the danger of extrapolating from predictions of inappropriate models.
```{r}
# another way to get the same result
ggplot(data = gapminder,
       mapping = aes(x = gdpPercap,
                     y = lifeExp)) +
  geom_point() + 
  geom_smooth(method = 'lm')
```

Data is quite bunched up against the left side. 
Gross Domestic Product per capita is not normally distributed across our country years. 
The x-axis scale would probably look better if it were transformed from a linear scale to a log scale. 
For this we can use a function called `scale_x_log10()`. 
As you might expect this function scales the x-axis of a plot to a log 10 basis. 
To use it we just add it to the plot:
```{r}
p<-ggplot(data= gapminder,
          mapping = aes(x= gdpPercap,
                        y= lifeExp))
p + geom_point() + 
  geom_smooth(method = 'gam') +
  scale_x_log10()
```

The labels on the tick-marks can be controlled through the `scale_*` functions.
Please notice that this we are using another library to have our tick labels in the dollar format. 
```{r}
p + geom_point() + 
  geom_smooth(method = 'gam') +
  scale_x_log10(labels = scales:: dollar)
```

The viz above already is way more informative than the ones before, but there is more we can extract from the underlying data. 
For instance, now it may make sense to re-introduce the `lm` method we used before. 

In passing, also notice the use of different parameters in the viz. 
The `se` option commands the standard error, and we can switch it off by inputing `se=FALSE`. 
The `alpha` regulates the transparency of the objects, from 0 to 1. 
Further, we can add info and make more it *publication ready*.
```{r}
p <- ggplot(data = gapminder,
            mapping = aes(x = gdpPercap,
                          y = lifeExp)) 
p + geom_point(alpha = 0.3) +
  geom_smooth(color = "orange", se = FALSE, linewidth = 1, method = "lm") +
  scale_x_log10(labels = scales:: dollar) +
  labs(x= 'GDP per capita', 
       y= 'Life Expectancy in Years', 
       title= 'Economic Growth and Life Expectancy', 
       subtitle= 'Data points are country-years', 
       caption= 'Source: Gapminder.')
```

Another way to think about the underlying data is to remind ourselves about the groups we have, represented by the `continent` variable.
In the code below, we include colours as an aesthetic, and map it on continents.
Notice that, by including also a `colour` parameter in the `geom_smooth` function, we are overriding the `colour` mapping in the `ggplot` function.
This has important consequences. 
```{r}
ggplot(data = gapminder,
            mapping = aes(x = gdpPercap,
                          y = lifeExp,
                          color= continent)) + 
  geom_point(alpha = 0.3) +
  geom_smooth(color = "orange", se = FALSE, linewidth = 1, method = "lm") +
  scale_x_log10(labels = scales:: dollar)
```

Indeed, see what happens when we do not override it.
We can immediately appreciate that the slope of our regression is radically different depending on the groups - consider this your introduction to the *dangers of pooling*. 
```{r}
ggplot(data = gapminder,
            mapping = aes(x = gdpPercap,
                          y = lifeExp,
                          color= continent)) + 
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  scale_x_log10(labels = scales:: dollar) 
```

However, this has become too cluttered, and it's hard to understand what's going on with all these colours and lines.
We reached saturation and need to revert to a simpler plot. 
```{r}
ggplot(data = gapminder,
            mapping = aes(x = gdpPercap,
                          y = lifeExp)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", colour="orange", fill="grey90") +
  facet_wrap(~continent) + 
  scale_x_log10(labels = scales:: dollar) +
  theme_minimal() +
  labs(x= 'GDP per capita', 
       y= 'Life Expectancy in Years', 
       title= 'Economic Growth and Life Expectancy', 
       subtitle= 'Data points are country-years', 
       caption= 'Source: Gapminder.')
```

What you observe above is variously termed as a small multiple visualisation, or faceted visualisation. 
The key point is that we break down the data in meaningful groups, and analyse them separately.
This enables us to see more clearly similarities and differences.
Remember, all analyses are comparisons. 

A radically different take is to exploit the time dimension.
```{r}
gapminder |>
  filter(continent %in% c("Asia", "Africa", "Europe", "Americas")) |>
  ggplot(aes(x = year, y = gdpPercap)) +
  geom_line(color="gray80", aes(group = country)) +
  geom_smooth(linewidth = 1, method = "loess", se = FALSE) +
  scale_y_log10(labels=scales::dollar) +
  facet_wrap(~ continent, ncol = 2) +
  theme_minimal() +
  labs(x = "Year",
         y = "GDP per capita",
         title = "GDP per capita on Five Continents")
```

## UN Votes
Data here directly from the library, exactly as in the case of `gapminder`.
How many tables are we dealing with?
```{r}
library(unvotes)
un_votes <- unvotes::un_votes
un_roll_calls <- unvotes::un_roll_calls
```

Get a quick glimpse of the distribution of votes.
```{r}
un_votes |> 
  count(vote, sort = TRUE)
# again, remember we can achieve the same results in many different ways
# base R
with(un_votes,
  tapply(X = vote, INDEX = vote, FUN = length) ) 
# data.table - super fast and memory efficient, but some find syntax a bit complex
data.table::setDT(un_votes)[, .N, by = list(vote)]
```




## EP Data (documents)


## Polls (EE, de, means, aggregations)


